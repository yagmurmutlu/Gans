{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom numpy import zeros, ones\nfrom numpy.random import randn, randint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, Dropout\nfrom tensorflow.keras.utils import plot_model\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport cv2\nfrom PIL import Image\nimport random\nimport re\nfrom keras.preprocessing.image import img_to_array\n\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-03T06:53:46.729179Z","iopub.execute_input":"2022-09-03T06:53:46.729732Z","iopub.status.idle":"2022-09-03T06:53:46.745811Z","shell.execute_reply.started":"2022-09-03T06:53:46.729683Z","shell.execute_reply":"2022-09-03T06:53:46.743960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Define input image dimensions\nimg_rows = 128\nimg_cols = 128\nchannels = 1\nimg_shape = (img_rows, img_cols, channels)","metadata":{"execution":{"iopub.status.busy":"2022-09-03T06:53:46.748744Z","iopub.execute_input":"2022-09-03T06:53:46.749811Z","iopub.status.idle":"2022-09-03T06:53:46.761186Z","shell.execute_reply.started":"2022-09-03T06:53:46.749740Z","shell.execute_reply":"2022-09-03T06:53:46.759476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_discriminator(in_shape=(128,128,3)):\n    model = Sequential()\n    # normal\n    model.add(Conv2D(128, (3,3), padding='same', input_shape=in_shape))\n    model.add(LeakyReLU(alpha=0.2))\n    # downsample to 64x64\n    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # downsample to 32x32\n    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # downsample to 16x16\n    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # downsample to 8x8\n    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # classifier\n    model.add(Flatten())\n    model.add(Dropout(0.4))\n    model.add(Dense(1, activation='sigmoid'))\n    # compile model\n    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-09-03T06:53:46.769380Z","iopub.execute_input":"2022-09-03T06:53:46.770727Z","iopub.status.idle":"2022-09-03T06:53:46.791456Z","shell.execute_reply.started":"2022-09-03T06:53:46.770634Z","shell.execute_reply":"2022-09-03T06:53:46.789874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Verify the model summary\ntest_discr = define_discriminator()\nprint(test_discr.summary())\nplot_model(test_discr, to_file='disc_model.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-03T06:53:46.798070Z","iopub.execute_input":"2022-09-03T06:53:46.798711Z","iopub.status.idle":"2022-09-03T06:53:47.360759Z","shell.execute_reply.started":"2022-09-03T06:53:46.798663Z","shell.execute_reply":"2022-09-03T06:53:47.358872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the standalone generator model\n# Generator must generate 128x128x3 images that can be fed into the discriminator. \n# So, we start with enough nodes in the dense layer that can be gradually upscaled\n#to 128x128x3. \ndef define_generator(latent_dim):\n    model = Sequential()\n    # Define number of nodes that can be gradually reshaped and upscaled to 128x128x3\n    n_nodes = 128 * 8 * 8 #8192 nodes\n    model.add(Dense(n_nodes, input_dim=latent_dim))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Reshape((8, 8, 128)))\n    # upsample to 16x16\n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # upsample to 32x32\n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # upsample to 64x64\n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # upsample to 128x128\n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # output layer 128x128x3\n    model.add(Conv2D(3, (8,8), activation='tanh', padding='same')) #tanh goes from [-1,1]\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-09-03T06:53:47.364690Z","iopub.execute_input":"2022-09-03T06:53:47.365788Z","iopub.status.idle":"2022-09-03T06:53:47.381874Z","shell.execute_reply.started":"2022-09-03T06:53:47.365701Z","shell.execute_reply":"2022-09-03T06:53:47.380315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_gen = define_generator(100)\nprint(test_gen.summary())\nplot_model(test_gen, to_file='generator_model.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-03T06:53:47.384198Z","iopub.execute_input":"2022-09-03T06:53:47.385155Z","iopub.status.idle":"2022-09-03T06:53:48.003716Z","shell.execute_reply.started":"2022-09-03T06:53:47.385099Z","shell.execute_reply":"2022-09-03T06:53:48.002018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the combined generator and discriminator model, for updating the generator\ndef define_gan(g_model, d_model):\n    # make weights in the discriminator not trainable\n    d_model.trainable = False\n    # connect them\n    model = Sequential()\n    # add generator\n    model.add(g_model)\n    # add the discriminator\n    model.add(d_model)\n    # compile model\n    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-09-03T06:53:48.012307Z","iopub.execute_input":"2022-09-03T06:53:48.016225Z","iopub.status.idle":"2022-09-03T06:53:48.029415Z","shell.execute_reply.started":"2022-09-03T06:53:48.016167Z","shell.execute_reply":"2022-09-03T06:53:48.027823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_gan = define_gan(test_gen, test_discr)\nprint(test_gan.summary())\nplot_model(test_gan, to_file='combined_model.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-03T06:53:48.036461Z","iopub.execute_input":"2022-09-03T06:53:48.039540Z","iopub.status.idle":"2022-09-03T06:53:48.505296Z","shell.execute_reply.started":"2022-09-03T06:53:48.039494Z","shell.execute_reply":"2022-09-03T06:53:48.503080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to sample some random real images\ndef generate_real_samples(dataset, n_samples):\n    ix = randint(0, dataset.shape[0], n_samples)\n    X = dataset[ix]\n    y = ones((n_samples, 1)) # Class labels for real images are 1\n    return X, y","metadata":{"execution":{"iopub.status.busy":"2022-09-03T06:53:48.511029Z","iopub.execute_input":"2022-09-03T06:53:48.513825Z","iopub.status.idle":"2022-09-03T06:53:48.524069Z","shell.execute_reply.started":"2022-09-03T06:53:48.513748Z","shell.execute_reply":"2022-09-03T06:53:48.522822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to generate random latent points\ndef generate_latent_points(latent_dim, n_samples):\n    x_input = randn(latent_dim * n_samples)\n    x_input = x_input.reshape(n_samples, latent_dim) #Reshape to be provided as input to the generator. \n    return x_input\n\n# Function to generate fake images using latent vectors\ndef generate_fake_samples(g_model, latent_dim, n_samples):\n    x_input = generate_latent_points(latent_dim, n_samples) #Generate latent points as input to the generator\n    X = g_model.predict(x_input) #Use the generator to generate fake images\n    y = zeros((n_samples, 1)) # Class labels for fake images are 0\n    return X, y","metadata":{"execution":{"iopub.status.busy":"2022-09-03T06:53:48.532593Z","iopub.execute_input":"2022-09-03T06:53:48.534302Z","iopub.status.idle":"2022-09-03T06:53:48.547035Z","shell.execute_reply.started":"2022-09-03T06:53:48.534262Z","shell.execute_reply":"2022-09-03T06:53:48.545305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to save Plots after every n number of epochs\ndef save_plot(examples, epoch, n=3):\n    # scale images from [-1,1] to [0,1] so we can plot\n    examples = (examples + 1) / 2.0\n    for i in range(n * n):\n        plt.subplot(n, n, 1 + i)\n        plt.axis('off')\n        plt.imshow(examples[i])\n    # save plot to a file so we can view how generated images evolved over epochs\n    filename = 'generated_plot_128x128_e%03d.png' % (epoch+1)\n    plt.savefig(filename)\n    plt.close()","metadata":{"execution":{"iopub.status.busy":"2022-09-03T06:53:48.551558Z","iopub.execute_input":"2022-09-03T06:53:48.556944Z","iopub.status.idle":"2022-09-03T06:53:48.568279Z","shell.execute_reply.started":"2022-09-03T06:53:48.556904Z","shell.execute_reply":"2022-09-03T06:53:48.566855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to summarize performance periodically. \n# \ndef summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n    # Fetch real images\n    X_real, y_real = generate_real_samples(dataset, n_samples)\n    # evaluate discriminator on real images - get accuracy\n    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n    # Generate fake images\n    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n    # evaluate discriminator on fake images - get accuracy\n    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n    # Print discriminate accuracies on ral and fake images. \n    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n    # save generated images periodically using the save_plot function\n    save_plot(x_fake, epoch)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-03T06:53:48.574443Z","iopub.execute_input":"2022-09-03T06:53:48.575590Z","iopub.status.idle":"2022-09-03T06:53:48.588677Z","shell.execute_reply.started":"2022-09-03T06:53:48.575336Z","shell.execute_reply":"2022-09-03T06:53:48.587254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train the generator and discriminator by enumerating batches and epochs. \n\ndef train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=128):\n    bat_per_epo = int(dataset.shape[0] / n_batch)\n    half_batch = int(n_batch / 2) #Disc. trained on half batch real and half batch fake images\n    #  enumerate epochs\n    for i in range(n_epochs):\n        # enumerate batches \n        for j in range(bat_per_epo):\n            # Fetch random 'real' images\n            X_real, y_real = generate_real_samples(dataset, half_batch)\n            # Train the discriminator using real images\n            d_loss1, _ = d_model.train_on_batch(X_real, y_real)\n            # generate 'fake' images \n            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n            # Train the discriminator using fake images\n            d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n            # Generate latent vectors as input for the generator\n            X_gan = generate_latent_points(latent_dim, n_batch)\n            # Label generated (fake) mages as 1 to fool the discriminator \n            y_gan = ones((n_batch, 1))\n            # Train the generator (via the discriminator's error)\n            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n            # Report disc. and gen losses. \n            print('Epoch>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n                (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n        # evaluate the model performance, sometimes\n        if (i+1) % 10 == 0:\n            summarize_performance(i, g_model, d_model, dataset, latent_dim)\n            # save the generator model\n            filename = 'generator_model_128x128_%03d.h5' % (i+1)\n            g_model.save(filename)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-03T06:53:48.599402Z","iopub.execute_input":"2022-09-03T06:53:48.602962Z","iopub.status.idle":"2022-09-03T06:53:48.619742Z","shell.execute_reply.started":"2022-09-03T06:53:48.602919Z","shell.execute_reply":"2022-09-03T06:53:48.618298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to get the files in proper order\ndef sorted_alphanumeric(data):  \n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n    return sorted(data,key = alphanum_key)","metadata":{"execution":{"iopub.status.busy":"2022-09-03T06:53:48.622381Z","iopub.execute_input":"2022-09-03T06:53:48.623943Z","iopub.status.idle":"2022-09-03T06:53:48.635435Z","shell.execute_reply.started":"2022-09-03T06:53:48.623495Z","shell.execute_reply":"2022-09-03T06:53:48.633875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIZE = 128\n_img = []\npath = '../input/face-mask-lite-dataset/without_mask'\nfiles = os.listdir(path)\nfiles = sorted_alphanumeric(files)\nfor i in tqdm(files):     \n    img = cv2.imread(path + '/'+i,1)\n    # open cv reads images in BGR format so we have to convert it to RGB\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    #resizing image\n    img = cv2.resize(img, (SIZE, SIZE))\n    img = (img - 127.5) / 127.5\n    img = img.astype(float)\n    _img.append(img_to_array(img))","metadata":{"execution":{"iopub.status.busy":"2022-09-03T06:53:48.637989Z","iopub.execute_input":"2022-09-03T06:53:48.639289Z","iopub.status.idle":"2022-09-03T07:03:40.746251Z","shell.execute_reply.started":"2022-09-03T06:53:48.639247Z","shell.execute_reply":"2022-09-03T07:03:40.744784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = np.array(_img)\n# size of the latent space\nlatent_dim = 100\n# create the discriminator using our pre-defined function\nd_model = define_discriminator()\n# create the generator using our pre-defined function\ng_model = define_generator(latent_dim)\n# create the gan  using our pre-defined function\ngan_model = define_gan(g_model, d_model)\n\n# train model\ntrain(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=500)","metadata":{"execution":{"iopub.status.busy":"2022-09-03T07:03:40.748257Z","iopub.execute_input":"2022-09-03T07:03:40.749052Z","iopub.status.idle":"2022-09-03T07:23:20.821349Z","shell.execute_reply.started":"2022-09-03T07:03:40.749008Z","shell.execute_reply":"2022-09-03T07:23:20.819400Z"},"trusted":true},"execution_count":null,"outputs":[]}]}